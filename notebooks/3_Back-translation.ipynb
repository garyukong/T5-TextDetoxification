{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Config,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    GenerationConfig,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    pipeline,\n",
    "    MarianMTModel,\n",
    "    MarianTokenizer,\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from typing import Dict, Union, Optional, Tuple, List, Any\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the DEVICE to cuda\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set path for raw dataset dictionary\n",
    "RAW_DATASET_PATH = \"../data/processed/raw_dataset.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizers and models\n",
    "tokenizer_toxicity = RobertaTokenizer.from_pretrained(\"SkolkovoInstitute/roberta_toxicity_classifier\")\n",
    "model_toxicity = RobertaForSequenceClassification.from_pretrained(\"SkolkovoInstitute/roberta_toxicity_classifier\").to(DEVICE)\n",
    "tokenizer_acceptability = AutoTokenizer.from_pretrained(\"iproskurina/tda-bert-en-cola\")\n",
    "model_acceptability = AutoModelForSequenceClassification.from_pretrained(\"iproskurina/tda-bert-en-cola\").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_datasets = DatasetDict.load_from_disk(RAW_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model variables\n",
    "model_bleurt = None\n",
    "model_bertscore = None\n",
    "model_sacrebleu = None\n",
    "\n",
    "def calc_sacrebleu(refs, preds):\n",
    "    \"\"\"\n",
    "    Calculates the SacreBLEU score.\n",
    "\n",
    "    Args:\n",
    "        refs (list): List of reference sentences\n",
    "        preds (list): List of predicted sentences\n",
    "    \n",
    "    Returns:\n",
    "        results (float): SacreBLEU score\n",
    "    \"\"\"\n",
    "    global model_sacrebleu\n",
    "\n",
    "    if model_sacrebleu is None:\n",
    "        model_sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "    results = model_sacrebleu.compute(predictions=preds, references=refs)[\"score\"]\n",
    "    results = results/100\n",
    "\n",
    "    return results\n",
    "\n",
    "def calc_bert_score(\n",
    "    refs, preds, model_type=\"microsoft/deberta-large-mnli\", output_mean=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculates BERT score per line. Note: https://docs.google.com/spreadsheets/d/1RKOVpselB98Nnh_EOC4A2BYn8_201tmPODpNWu4w7xI/edit#gid=0 lists the best performing models\n",
    "    Args:\n",
    "        refs (list): List of reference sentences.\n",
    "        y_pred (list): List of predicted sentences.\n",
    "        model_type (str): Type of BERT model to use.\n",
    "        output_mean (bool): Whether to output the mean of the scores.\n",
    "\n",
    "    Returns:\n",
    "        list of precision, recall, f1 scores.\n",
    "\n",
    "    \"\"\"\n",
    "    global model_bertscore\n",
    "\n",
    "    if model_bertscore is None:\n",
    "        model_bertscore = evaluate.load(\"bertscore\")\n",
    "        \n",
    "    results = model_bertscore.compute(predictions=preds, references=refs, model_type=model_type)\n",
    "    precision = np.array(results[\"precision\"])\n",
    "    recall = np.array(results[\"recall\"])\n",
    "    f1 = np.array(results[\"f1\"])\n",
    "    \n",
    "    if output_mean:\n",
    "        precision = precision.mean()\n",
    "        recall = recall.mean()\n",
    "        f1 = f1.mean()\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def calc_bleurt(refs, preds, checkpoint=\"BLEURT-20_D12\", output_mean = True):\n",
    "    \"\"\"\n",
    "    Calculates BLEURT score per line.\n",
    "\n",
    "    Args:\n",
    "        refs (list): List of reference sentences.\n",
    "        preds (list): List of predicted sentences.\n",
    "        output_type (str): Type of output to return. Either 'numpy' or 'list'.\n",
    "\n",
    "    Returns:\n",
    "        list/array of BLEURT scores.\n",
    "    \"\"\"\n",
    "    global model_bleurt\n",
    "\n",
    "    if model_bleurt is None:\n",
    "        model_bleurt = evaluate.load(\"bleurt\", module_type=\"metric\", checkpoint=checkpoint)\n",
    "\n",
    "    results = np.array(model_bleurt.compute(predictions=preds, references=refs)[\"scores\"])\n",
    "\n",
    "    if output_mean:\n",
    "        results = results.mean()\n",
    "\n",
    "    return results\n",
    "\n",
    "def calc_tox_acceptability(\n",
    "    data,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    output_score=True,\n",
    "    output_mean=True):\n",
    "    \"\"\"\n",
    "    Calculates toxicity and acceptability scores for a given dataset.\n",
    "\n",
    "    Args:\n",
    "        data = list of strings to be evaluated\n",
    "        tokenizer = tokenizer for the model\n",
    "        model = model to be used for evaluation\n",
    "        output_score = whether to output the score or the label\n",
    "        output_mean = whether to output the mean of the scores or the scores for each sentence\n",
    "    \n",
    "    Returns:\n",
    "        array of toxicity and acceptability scores.\n",
    "    \"\"\"  \n",
    "    inputs = tokenizer(data, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs)[\"logits\"]\n",
    "        if output_score:\n",
    "            result = torch.nn.functional.softmax(logits, dim=1)[:, 1]\n",
    "        else:\n",
    "            result = logits.argmax(1).data\n",
    "        result = result.cpu().numpy()\n",
    "\n",
    "    if output_mean:\n",
    "        result = result.mean()\n",
    "        \n",
    "    return result\n",
    "\n",
    "def evaluate_metrics(\n",
    "    refs,\n",
    "    preds,\n",
    "    tokenizer_toxicity=tokenizer_toxicity,\n",
    "    model_toxicity=model_toxicity,\n",
    "    tokenizer_acceptability=tokenizer_acceptability,\n",
    "    model_acceptability=model_acceptability,\n",
    "    to_neutral=True,\n",
    "    weights={\n",
    "        \"BLEU\": 0.2,\n",
    "        \"STA\": 0.4,\n",
    "        \"Acceptability\": 0.2,\n",
    "        \"BERT_Score\": 0.2\n",
    "    },\n",
    "    include_bleurt=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates and returns a dictionary of evaluation metrics\n",
    "\n",
    "    Args:\n",
    "        refs (list): list of strings (reference)\n",
    "        preds (list): list of strings (predictions)\n",
    "        tokenizer_toxicity (tokenizer): tokenizer for toxicity model\n",
    "        model_toxicity (model): toxicity model\n",
    "        tokenizer_acceptability (tokenizer): tokenizer for acceptability model\n",
    "        model_acceptability (model): acceptability model\n",
    "        to_neutral (bool): whether the goal is to transfer to neutral (True) or to toxic (False)\n",
    "        weights (dict): dictionary of weights for each metric\n",
    "        include_bleurt (bool): whether to include BLEURT score in the output\n",
    "\n",
    "    Returns:\n",
    "        results (dict): dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    bleu = calc_sacrebleu(refs, preds)\n",
    "\n",
    "    # Calculate toxicity classification\n",
    "    # tox_ref = calc_tox_acceptability(refs, tokenizer_toxicity, model_toxicity, output_score=False, output_mean=False)\n",
    "    tox_pred = calc_tox_acceptability(preds, tokenizer_toxicity, model_toxicity, output_score=False, output_mean=False)\n",
    "\n",
    "    # Calculate style transfer accuracy as proportion of sentences that were correctly classified (as non-toxic / toxic)\n",
    "    if to_neutral:\n",
    "        sta_correct_label = 0\n",
    "    else:\n",
    "        sta_correct_label = 1\n",
    "\n",
    "    # sta_ref = (tox_ref == sta_correct_label).sum() / len(tox_ref)\n",
    "    sta_pred = (tox_pred == sta_correct_label).sum() / len(tox_pred)\n",
    "    # sta_pct = sta_pred / sta_ref\n",
    "\n",
    "    # Calculate acceptability scores\n",
    "    # acc_ref = calc_tox_acceptability(refs, tokenizer_acceptability, model_acceptability)\n",
    "    acc_pred = calc_tox_acceptability(preds, tokenizer_acceptability, model_acceptability)\n",
    "    # acc_pct = acc_pred / acc_ref\n",
    "\n",
    "    # Calculate similarity score\n",
    "    bert_score_f1 = calc_bert_score(refs, preds, model_type=\"distilbert-base-uncased\")[2]\n",
    "\n",
    "    # Calculate BLEURT score if include_bleurt is True\n",
    "    bleurt = None\n",
    "    if include_bleurt:\n",
    "        bleurt = calc_bleurt(refs, preds)\n",
    "\n",
    "    # Calculate composite score\n",
    "    composite_score = weights[\"BLEU\"] * bleu + weights[\"STA\"] * sta_pred + weights[\"Acceptability\"] * acc_pred + weights[\"BERT_Score\"] * bert_score_f1\n",
    "\n",
    "    # Return a dictionary of metrics\n",
    "    results = {\n",
    "        \"BLEU\": bleu,\n",
    "        \"STA\": sta_pred,\n",
    "        # \"STA_pct\": sta_pct,\n",
    "        \"FLU\": acc_pred,\n",
    "        # \"Acceptability_pct\": acc_pct,\n",
    "        \"SEM\": bert_score_f1,\n",
    "        \"Overall\": composite_score,\n",
    "    }\n",
    "    if include_bleurt:\n",
    "        results[\"BLEURT\"] = bleurt\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-Translation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to download data for a language\n",
    "def download(model_name):\n",
    "  tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "  model = MarianMTModel.from_pretrained(model_name)\n",
    "  return tokenizer, model\n",
    "\n",
    "# download model for English -> Romance\n",
    "tmp_lang_tokenizer, tmp_lang_model = download('Helsinki-NLP/opus-mt-en-ROMANCE')\n",
    "\n",
    "# download model for Romance -> English\n",
    "src_lang_tokenizer, src_lang_model = download('Helsinki-NLP/opus-mt-ROMANCE-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(texts, model, tokenizer, language):\n",
    "  \"\"\"Translate texts into a target language\"\"\"\n",
    "  # Format the text as expected by the model\n",
    "  formatter_fn = lambda txt: f\"{txt}\" if language == \"en\" else f\">>{language}<< {txt}\"\n",
    "  formatted_texts = [formatter_fn(txt) for txt in texts]\n",
    "\n",
    "  # Tokenize (text to tokens)\n",
    "  tokens = tokenizer(formatted_texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "  # Translate\n",
    "  translated = model.generate(**tokens)\n",
    "\n",
    "  # Decode (tokens to text)\n",
    "  translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "  return translated_texts\n",
    "\n",
    "def back_translate(texts, language_src, language_dst):\n",
    "    \"\"\"Implements back translation\"\"\"\n",
    "    all_back_translated_texts = []\n",
    "\n",
    "    # Iterate over each text rather than each language\n",
    "    for text in tqdm(texts):\n",
    "        back_translated_texts_for_text = []\n",
    "\n",
    "        # Check if language_dst is a list or a single language\n",
    "        for lang in language_dst:\n",
    "            \n",
    "            # Translate from source to target language\n",
    "            with torch.no_grad():\n",
    "                translated = translate([text], tmp_lang_model, tmp_lang_tokenizer, lang)\n",
    "                back_translated = translate(translated, src_lang_model, src_lang_tokenizer, language_src)\n",
    "            \n",
    "            # Collect the back-translated texts for this particular text\n",
    "            back_translated_texts_for_text.extend(back_translated)\n",
    "\n",
    "        # Collect all the back-translated versions for each text\n",
    "        all_back_translated_texts.extend(back_translated_texts_for_text)\n",
    "\n",
    "    return all_back_translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnum, were right : theres a sucker born ever...</td>\n",
       "      <td>Barnum, were right : theres a baby born every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barnum, were right : theres a sucker born ever...</td>\n",
       "      <td>Barnum, were right : theres a baby born every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnum, were right : theres a sucker born ever...</td>\n",
       "      <td>Barnum, were right : theres a baby born every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barnum, were right : theres a sucker born ever...</td>\n",
       "      <td>Barnum, were right : theres a baby born every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barnum, were right : theres a sucker born ever...</td>\n",
       "      <td>Barnum, were right : theres a baby born every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>So dont try to act like you know what the fuck...</td>\n",
       "      <td>So dont try to act like you know what is going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>So dont try to act like you know what the fuck...</td>\n",
       "      <td>So dont try to act like you know what is going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>So dont try to act like you know what the fuck...</td>\n",
       "      <td>So dont try to act like you know what is going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>So dont try to act like you know what the fuck...</td>\n",
       "      <td>So dont try to act like you know what is going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>So dont try to act like you know what the fuck...</td>\n",
       "      <td>So dont try to act like you know what is going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Does the bear pope shit in the woods?</td>\n",
       "      <td>Does the bear pope in the woods?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Does the bear pope shit in the woods?</td>\n",
       "      <td>Does the bear pope in the woods?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Does the bear pope shit in the woods?</td>\n",
       "      <td>Does the bear pope in the woods?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Does the bear pope shit in the woods?</td>\n",
       "      <td>Does the bear pope in the woods?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Does the bear pope shit in the woods?</td>\n",
       "      <td>Does the bear pope in the woods?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Dreadstar, littlemountain5, and some jerk on t...</td>\n",
       "      <td>Dreadstar, littlemountain5, and some one on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dreadstar, littlemountain5, and some jerk on t...</td>\n",
       "      <td>Dreadstar, littlemountain5, and some one on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dreadstar, littlemountain5, and some jerk on t...</td>\n",
       "      <td>Dreadstar, littlemountain5, and some one on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dreadstar, littlemountain5, and some jerk on t...</td>\n",
       "      <td>Dreadstar, littlemountain5, and some one on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dreadstar, littlemountain5, and some jerk on t...</td>\n",
       "      <td>Dreadstar, littlemountain5, and some one on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>He was only twenty fucking years old.</td>\n",
       "      <td>He was only twenty years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>He was only twenty fucking years old.</td>\n",
       "      <td>He was only twenty years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>He was only twenty fucking years old.</td>\n",
       "      <td>He was only twenty years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>He was only twenty fucking years old.</td>\n",
       "      <td>He was only twenty years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>He was only twenty fucking years old.</td>\n",
       "      <td>He was only twenty years old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Paprocki is denying people in same sex marriag...</td>\n",
       "      <td>Paprocki is denying homosexual marriage funera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Paprocki is denying people in same sex marriag...</td>\n",
       "      <td>Paprocki is denying homosexual marriage funera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Paprocki is denying people in same sex marriag...</td>\n",
       "      <td>Paprocki is denying homosexual marriage funera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Paprocki is denying people in same sex marriag...</td>\n",
       "      <td>Paprocki is denying homosexual marriage funera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Paprocki is denying people in same sex marriag...</td>\n",
       "      <td>Paprocki is denying homosexual marriage funera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Is drinking this nasty ass redbull and vodka t...</td>\n",
       "      <td>Is drinking this redbull and vodka that gave me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Is drinking this nasty ass redbull and vodka t...</td>\n",
       "      <td>Is drinking this redbull and vodka that gave me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Is drinking this nasty ass redbull and vodka t...</td>\n",
       "      <td>Is drinking this redbull and vodka that gave me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Is drinking this nasty ass redbull and vodka t...</td>\n",
       "      <td>Is drinking this redbull and vodka that gave me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Is drinking this nasty ass redbull and vodka t...</td>\n",
       "      <td>Is drinking this redbull and vodka that gave me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>That shit was dirty as hell! lmao</td>\n",
       "      <td>That thing was too dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>That shit was dirty as hell! lmao</td>\n",
       "      <td>That thing was too dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>That shit was dirty as hell! lmao</td>\n",
       "      <td>That thing was too dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>That shit was dirty as hell! lmao</td>\n",
       "      <td>That thing was too dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>That shit was dirty as hell! lmao</td>\n",
       "      <td>That thing was too dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "      <td>Why do the people vote for stuff that screws t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>He must be a fool if he's expecting turkey to ...</td>\n",
       "      <td>He must be mistaken if he's expecting turkey t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>He must be a fool if he's expecting turkey to ...</td>\n",
       "      <td>He must be mistaken if he's expecting turkey t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>He must be a fool if he's expecting turkey to ...</td>\n",
       "      <td>He must be mistaken if he's expecting turkey t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>He must be a fool if he's expecting turkey to ...</td>\n",
       "      <td>He must be mistaken if he's expecting turkey t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>He must be a fool if he's expecting turkey to ...</td>\n",
       "      <td>He must be mistaken if he's expecting turkey t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               source  \\\n",
       "0   Barnum, were right : theres a sucker born ever...   \n",
       "1   Barnum, were right : theres a sucker born ever...   \n",
       "2   Barnum, were right : theres a sucker born ever...   \n",
       "3   Barnum, were right : theres a sucker born ever...   \n",
       "4   Barnum, were right : theres a sucker born ever...   \n",
       "5   So dont try to act like you know what the fuck...   \n",
       "6   So dont try to act like you know what the fuck...   \n",
       "7   So dont try to act like you know what the fuck...   \n",
       "8   So dont try to act like you know what the fuck...   \n",
       "9   So dont try to act like you know what the fuck...   \n",
       "10              Does the bear pope shit in the woods?   \n",
       "11              Does the bear pope shit in the woods?   \n",
       "12              Does the bear pope shit in the woods?   \n",
       "13              Does the bear pope shit in the woods?   \n",
       "14              Does the bear pope shit in the woods?   \n",
       "15  Dreadstar, littlemountain5, and some jerk on t...   \n",
       "16  Dreadstar, littlemountain5, and some jerk on t...   \n",
       "17  Dreadstar, littlemountain5, and some jerk on t...   \n",
       "18  Dreadstar, littlemountain5, and some jerk on t...   \n",
       "19  Dreadstar, littlemountain5, and some jerk on t...   \n",
       "20              He was only twenty fucking years old.   \n",
       "21              He was only twenty fucking years old.   \n",
       "22              He was only twenty fucking years old.   \n",
       "23              He was only twenty fucking years old.   \n",
       "24              He was only twenty fucking years old.   \n",
       "25  Paprocki is denying people in same sex marriag...   \n",
       "26  Paprocki is denying people in same sex marriag...   \n",
       "27  Paprocki is denying people in same sex marriag...   \n",
       "28  Paprocki is denying people in same sex marriag...   \n",
       "29  Paprocki is denying people in same sex marriag...   \n",
       "30  Is drinking this nasty ass redbull and vodka t...   \n",
       "31  Is drinking this nasty ass redbull and vodka t...   \n",
       "32  Is drinking this nasty ass redbull and vodka t...   \n",
       "33  Is drinking this nasty ass redbull and vodka t...   \n",
       "34  Is drinking this nasty ass redbull and vodka t...   \n",
       "35                  That shit was dirty as hell! lmao   \n",
       "36                  That shit was dirty as hell! lmao   \n",
       "37                  That shit was dirty as hell! lmao   \n",
       "38                  That shit was dirty as hell! lmao   \n",
       "39                  That shit was dirty as hell! lmao   \n",
       "40  Why do the people vote for stuff that screws t...   \n",
       "41  Why do the people vote for stuff that screws t...   \n",
       "42  Why do the people vote for stuff that screws t...   \n",
       "43  Why do the people vote for stuff that screws t...   \n",
       "44  Why do the people vote for stuff that screws t...   \n",
       "45  He must be a fool if he's expecting turkey to ...   \n",
       "46  He must be a fool if he's expecting turkey to ...   \n",
       "47  He must be a fool if he's expecting turkey to ...   \n",
       "48  He must be a fool if he's expecting turkey to ...   \n",
       "49  He must be a fool if he's expecting turkey to ...   \n",
       "\n",
       "                                               target  \n",
       "0   Barnum, were right : theres a baby born every ...  \n",
       "1   Barnum, were right : theres a baby born every ...  \n",
       "2   Barnum, were right : theres a baby born every ...  \n",
       "3   Barnum, were right : theres a baby born every ...  \n",
       "4   Barnum, were right : theres a baby born every ...  \n",
       "5   So dont try to act like you know what is going...  \n",
       "6   So dont try to act like you know what is going...  \n",
       "7   So dont try to act like you know what is going...  \n",
       "8   So dont try to act like you know what is going...  \n",
       "9   So dont try to act like you know what is going...  \n",
       "10                   Does the bear pope in the woods?  \n",
       "11                   Does the bear pope in the woods?  \n",
       "12                   Does the bear pope in the woods?  \n",
       "13                   Does the bear pope in the woods?  \n",
       "14                   Does the bear pope in the woods?  \n",
       "15  Dreadstar, littlemountain5, and some one on th...  \n",
       "16  Dreadstar, littlemountain5, and some one on th...  \n",
       "17  Dreadstar, littlemountain5, and some one on th...  \n",
       "18  Dreadstar, littlemountain5, and some one on th...  \n",
       "19  Dreadstar, littlemountain5, and some one on th...  \n",
       "20                       He was only twenty years old  \n",
       "21                       He was only twenty years old  \n",
       "22                       He was only twenty years old  \n",
       "23                       He was only twenty years old  \n",
       "24                       He was only twenty years old  \n",
       "25  Paprocki is denying homosexual marriage funera...  \n",
       "26  Paprocki is denying homosexual marriage funera...  \n",
       "27  Paprocki is denying homosexual marriage funera...  \n",
       "28  Paprocki is denying homosexual marriage funera...  \n",
       "29  Paprocki is denying homosexual marriage funera...  \n",
       "30    Is drinking this redbull and vodka that gave me  \n",
       "31    Is drinking this redbull and vodka that gave me  \n",
       "32    Is drinking this redbull and vodka that gave me  \n",
       "33    Is drinking this redbull and vodka that gave me  \n",
       "34    Is drinking this redbull and vodka that gave me  \n",
       "35                           That thing was too dirty  \n",
       "36                           That thing was too dirty  \n",
       "37                           That thing was too dirty  \n",
       "38                           That thing was too dirty  \n",
       "39                           That thing was too dirty  \n",
       "40  Why do the people vote for stuff that screws t...  \n",
       "41  Why do the people vote for stuff that screws t...  \n",
       "42  Why do the people vote for stuff that screws t...  \n",
       "43  Why do the people vote for stuff that screws t...  \n",
       "44  Why do the people vote for stuff that screws t...  \n",
       "45  He must be mistaken if he's expecting turkey t...  \n",
       "46  He must be mistaken if he's expecting turkey t...  \n",
       "47  He must be mistaken if he's expecting turkey t...  \n",
       "48  He must be mistaken if he's expecting turkey t...  \n",
       "49  He must be mistaken if he's expecting turkey t...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set languages\n",
    "languages = ['fr', 'es', 'it', 'pt', 'ro']\n",
    "num_languages = len(languages)\n",
    "\n",
    "# Create a copy of the dataset, selecting only 10 samples from each\n",
    "raw_datasets_train_copy = raw_datasets['train'].select(range(10))\n",
    "source = raw_datasets_train_copy['source']\n",
    "target = raw_datasets_train_copy['target']\n",
    "\n",
    "# Replicate the sentences according to the number of languages\n",
    "source_replicated = []\n",
    "for sentence in source:\n",
    "    for i in range(num_languages):\n",
    "        source_replicated.extend([sentence])\n",
    "\n",
    "target_replicated = []\n",
    "for sentence in target:\n",
    "    for i in range(num_languages):\n",
    "        target_replicated.extend([sentence])\n",
    "\n",
    "# Create a pandas dataframe\n",
    "df = pd.DataFrame()\n",
    "df['source'] = source_replicated\n",
    "df['target'] = target_replicated\n",
    "\n",
    "# Back translate the sentences and add to pandas dataframe\n",
    "df['source_bt'] = back_translate(source, \"en\", languages)\n",
    "df['target_bt'] = back_translate(target, \"en\", languages)\n",
    "\n",
    "# Delete rows with duplicate 'source_bt' or 'target_bt'\n",
    "print(f\"Before deleting duplicates: {len(df)}\")\n",
    "df = df[df['source'] != df['source_bt']]\n",
    "df = df[df['target'] != df['target_bt']]\n",
    "df = df.drop_duplicates(subset=['source_bt'])\n",
    "df = df.drop_duplicates(subset=['target_bt'])\n",
    "print(f\"After deleting duplicates: {len(df)}\")\n",
    "\n",
    "# Calculate toxicity scores for the candidate sentence pairs\n",
    "df['source_bt_toxicity'] = calc_tox_acceptability(df['source_bt'].tolist(), tokenizer_toxicity, model_toxicity, output_score=False, output_mean=False)\n",
    "df['target_bt_toxicity'] = calc_tox_acceptability(df['target_bt'].tolist(), tokenizer_toxicity, model_toxicity, output_score=False, output_mean=False)\n",
    "\n",
    "# Calculate acceptability scores for the candidate sentence pairs\n",
    "df['source_bt_acceptability'] = calc_tox_acceptability(df['source_bt'].tolist(), tokenizer_acceptability, model_acceptability, output_score=False, output_mean=False)\n",
    "df['target_bt_acceptability'] = calc_tox_acceptability(df['target_bt'].tolist(), tokenizer_acceptability, model_acceptability, output_score=False, output_mean=False)\n",
    "\n",
    "# Calculate similarity scores for the candidate sentence pairs - return the F1 score\n",
    "df['bt_similarity'] = calc_bert_score(df['source_bt'], df['target_bt'], model_type=\"distilbert-base-uncased\", output_mean=False)[2]\n",
    "\n",
    "# Create filters for the candidate sentence pairs\n",
    "## Filter 1: Toxicity\n",
    "df['f_toxicity'] = (df['source_bt_toxicity'] == 1) & (df['target_bt_toxicity'] == 0)\n",
    "\n",
    "## Filter 2: Acceptability\n",
    "df['f_acceptability'] = (df['source_bt_acceptability'] == 1) & (df['target_bt_acceptability'] == 1)\n",
    "\n",
    "## Filter 3: Similarity\n",
    "df['f_similarity'] = (df['bt_similarity'] > 0.9)\n",
    "\n",
    "# Save the dataframe as a pickle file\n",
    "df.to_pickle(\"../data/processed/back_translated_dataset.pkl\")\n",
    "\n",
    "# Create different datasets based on the filters\n",
    "df_all = df[df['f_toxicity'] & df['f_acceptability'] & df['f_similarity']]\n",
    "df_nosta = df[df['f_acceptability'] & df['f_similarity']]\n",
    "df_noflu = df[df['f_toxicity'] & df['f_similarity']]\n",
    "df_nosem = df[df['f_toxicity'] & df['f_acceptability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
