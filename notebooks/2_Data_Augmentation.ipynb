{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 16:53:35.894777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-10 16:53:35.894827: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-10 16:53:35.894854: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    MarianMTModel,\n",
    "    MarianTokenizer,\n",
    ")\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import GPUtil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Setting the DEVICE to cuda\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set path for raw dataset dictionary\n",
    "RAW_DATASET_PATH = \"../data/processed/raw_dataset.pkl\"\n",
    "\n",
    "# Load tokenizers and models for toxicity and acceptability\n",
    "tokenizer_toxicity = RobertaTokenizer.from_pretrained(\"SkolkovoInstitute/roberta_toxicity_classifier\")\n",
    "model_toxicity = RobertaForSequenceClassification.from_pretrained(\"SkolkovoInstitute/roberta_toxicity_classifier\").to(DEVICE)\n",
    "tokenizer_acceptability = AutoTokenizer.from_pretrained(\"iproskurina/tda-bert-en-cola\")\n",
    "model_acceptability = AutoModelForSequenceClassification.from_pretrained(\"iproskurina/tda-bert-en-cola\").to(DEVICE)\n",
    "\n",
    "# Load tokenizer and model for English -> Romance\n",
    "tmp_lang_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-ROMANCE')\n",
    "tmp_lang_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-ROMANCE').to(DEVICE)\n",
    "\n",
    "# Load tokenizer and model for Romance -> English\n",
    "src_lang_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ROMANCE-en')\n",
    "src_lang_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-ROMANCE-en').to(DEVICE)\n",
    "\n",
    "# Load dataset\n",
    "raw_datasets = DatasetDict.load_from_disk(RAW_DATASET_PATH)\n",
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 42\n",
    "SAMPLE_SIZE = 10000 # Number of samples to be generated\n",
    "ACCEPTABILITY_THRESHOLD_SOURCE = 0.6541633009910583 # Acceptability threshold for source language (mean of original)\n",
    "ACCEPTABILITY_THRESHOLD_TARGET = 0.7226778864860535 # Acceptability threshold for target language (mean of original)\n",
    "SIMILARITY_THRESHOLD = 0.9040371657728449 # Similarity threshold for source and target language (mean of original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_memory():\n",
    "    \"\"\"\n",
    "    Gets the GPU memory information.\n",
    "    \"\"\"\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    gpu = gpus[0]\n",
    "    print(f\"Total GPU memory: {gpu.memoryTotal}MB\")\n",
    "    print(f\"Free GPU memory: {gpu.memoryFree}MB\")\n",
    "    print(f\"Used GPU memory: {gpu.memoryUsed}MB\")\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"\n",
    "    Cleans up the GPU memory.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model variables\n",
    "model_bertscore = None\n",
    "\n",
    "def calc_bert_score(\n",
    "    refs, preds, model_type=\"distilbert-base-uncased\", batch_size=BATCH_SIZE, output_mean=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculates BERT score per line in batches.\n",
    "    Args:\n",
    "        refs (list): List of reference sentences.\n",
    "        preds (list): List of predicted sentences.\n",
    "        model_type (str): Type of BERT model to use.\n",
    "        batch_size (int): Number of examples per batch.\n",
    "        output_mean (bool): Whether to output the mean of the scores.\n",
    "\n",
    "    Returns:\n",
    "        list of precision, recall, f1 scores if output_mean=False.\n",
    "        mean of precision, recall, f1 scores if output_mean=True.\n",
    "    \"\"\"\n",
    "    global model_bertscore\n",
    "\n",
    "    if model_bertscore is None:\n",
    "        model_bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "    all_precision, all_recall, all_f1 = [], [], []\n",
    "    for i in tqdm(range(0, len(refs), batch_size)):\n",
    "        batch_refs = refs[i:i+batch_size]\n",
    "        batch_preds = preds[i:i+batch_size]\n",
    "        batch_results = model_bertscore.compute(predictions=batch_preds, references=batch_refs, model_type=model_type)\n",
    "        all_precision.extend(batch_results[\"precision\"])\n",
    "        all_recall.extend(batch_results[\"recall\"])\n",
    "        all_f1.extend(batch_results[\"f1\"])\n",
    "\n",
    "    if output_mean:\n",
    "        precision = np.mean(all_precision)\n",
    "        recall = np.mean(all_recall)\n",
    "        f1 = np.mean(all_f1)\n",
    "        return precision, recall, f1\n",
    "\n",
    "    return all_precision, all_recall, all_f1\n",
    "\n",
    "def calc_tox_acceptability(\n",
    "    data,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    output_score=True,\n",
    "    output_mean=True):\n",
    "    \"\"\"\n",
    "    Calculates toxicity and acceptability scores for a given dataset in batches.\n",
    "\n",
    "    Args:\n",
    "        data: list of strings to be evaluated\n",
    "        tokenizer: tokenizer for the model\n",
    "        model: model to be used for evaluation\n",
    "        batch_size: size of the batch for processing\n",
    "        output_score: whether to output the score or the label\n",
    "        output_mean: whether to output the mean of the scores or the scores for each sentence\n",
    "    \n",
    "    Returns:\n",
    "        Array of toxicity and acceptability scores.\n",
    "    \"\"\"  \n",
    "    all_results = []\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        batch_data = data[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_data, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs)[\"logits\"]\n",
    "            if output_score:\n",
    "                batch_results = torch.nn.functional.softmax(logits, dim=1)[:, 1]\n",
    "            else:\n",
    "                batch_results = logits.argmax(1)\n",
    "            all_results.append(batch_results.cpu().numpy())\n",
    "\n",
    "        del inputs\n",
    "        del logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if not output_mean:\n",
    "        return np.concatenate(all_results)\n",
    "\n",
    "    return np.mean(np.concatenate(all_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA to set tresholds for filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get acceptability scores for raw source and target sentences\n",
    "# raw_src_acceptability = calc_tox_acceptability(raw_datasets[\"train\"][\"source\"], tokenizer_acceptability, model_acceptability, output_score=True, output_mean=False)\n",
    "# raw_tgt_acceptability = calc_tox_acceptability(raw_datasets[\"train\"][\"target\"], tokenizer_acceptability, model_acceptability, output_score=True, output_mean=False)\n",
    "\n",
    "# # Calculate semantic similarity scores for raw source and target sentences\n",
    "# raw_similarity = calc_bert_score(raw_datasets[\"train\"][\"source\"], raw_datasets[\"train\"][\"target\"], model_type=\"distilbert-base-uncased\", output_mean=False)[2]\n",
    "\n",
    "# # Plot in density plots\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# axs[0].set_title(\"Acceptability scores for raw source and target sentences\")\n",
    "# axs[0].set_xlabel(\"Acceptability score\")\n",
    "# axs[0].set_ylabel(\"Density\")\n",
    "# axs[0].hist(raw_src_acceptability, bins=20, alpha=0.5, label=\"Source\")\n",
    "# axs[0].hist(raw_tgt_acceptability, bins=20, alpha=0.5, label=\"Target\")\n",
    "# axs[0].legend()\n",
    "\n",
    "# axs[1].set_title(\"Semantic similarity scores for raw source and target sentences\")\n",
    "# axs[1].set_xlabel(\"Semantic similarity score\")\n",
    "# axs[1].set_ylabel(\"Density\")\n",
    "# axs[1].hist(raw_similarity, bins=20, alpha=0.5)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate acceptability thresholds\n",
    "# ACCEPTABILITY_THRESHOLD_SOURCE = np.mean(raw_src_acceptability)\n",
    "# ACCEPTABILITY_THRESHOLD_TARGET = np.mean(raw_tgt_acceptability)\n",
    "\n",
    "# print(f\"acceptability_threshold_source: {ACCEPTABILITY_THRESHOLD_SOURCE}\")\n",
    "# print(f\"acceptability_threshold_target: {ACCEPTABILITY_THRESHOLD_TARGET}\")\n",
    "\n",
    "# # Calculate semantic similarity threshold\n",
    "# SIMILARITY_THRESHOLD = np.mean(raw_similarity)\n",
    "# print(f\"similarity_threshold: {SIMILARITY_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-Translation Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(batch_texts, model, tokenizer, language):\n",
    "    \"\"\"\n",
    "    Translate texts into a target language\n",
    "    \n",
    "    Args:\n",
    "        batch_texts (list): list of texts to be translated\n",
    "        model (model): MarianMTModel\n",
    "        tokenizer (tokenizer): MarianTokenizer\n",
    "        language (str): target language\n",
    "\n",
    "    Returns:\n",
    "        list of translated texts\n",
    "    \"\"\"\n",
    "    formatter_fn = lambda txt: f\">>{language}<<\" + txt if language != \"en\" else txt\n",
    "    formatted_texts = [formatter_fn(txt) for txt in batch_texts]\n",
    "\n",
    "    tokens = tokenizer(formatted_texts, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        translated = model.generate(**tokens, num_return_sequences=2)\n",
    "\n",
    "    translated_texts = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "\n",
    "    del tokens\n",
    "    del translated\n",
    "    cleanup()\n",
    "\n",
    "    return translated_texts\n",
    "\n",
    "def back_translate(texts, language_src, language_dst, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Implements back translation using batch processing\n",
    "    \n",
    "    Args:\n",
    "        texts (list): list of texts to be back translated\n",
    "        language_src (str): source language\n",
    "        language_dst (list): list of target languages\n",
    "        batch_size (int): batch size\n",
    "\n",
    "    Returns:\n",
    "        list of back translated texts    \n",
    "    \"\"\"\n",
    "    all_back_translated_texts = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        for lang in language_dst:\n",
    "            translated_batch = translate(batch, tmp_lang_model, tmp_lang_tokenizer, lang)\n",
    "            back_translated_batch = translate(translated_batch, src_lang_model, src_lang_tokenizer, language_src)\n",
    "            all_back_translated_texts.extend(back_translated_batch)\n",
    "\n",
    "    return all_back_translated_texts\n",
    "\n",
    "def make_back_translate_df(raw_datasets = raw_datasets,\n",
    "                           language_src = \"en\",\n",
    "                           language_dst = ['fr', 'es', 'it']):\n",
    "    \"\"\"\n",
    "    Makes a dataframe of back translated sentences\n",
    "\n",
    "    Args:\n",
    "        raw_datasets (dict): raw dataset dictionary\n",
    "        language_src (str): source language\n",
    "        language_dst (list): list of target languages\n",
    "\n",
    "    Returns:\n",
    "        dataframe of back translated sentences\n",
    "    \"\"\"\n",
    "    # Create a pandas dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Back translate the sentences and add to pandas dataframe\n",
    "    df['source_bt'] = back_translate(raw_datasets['train']['source'], language_src, language_dst)\n",
    "    df['target_bt'] = back_translate(raw_datasets['train']['target'], language_src, language_dst)\n",
    "\n",
    "    # Delete rows with duplicate 'source_bt' or 'target_bt'\n",
    "    df = df.drop_duplicates(subset=['source_bt'])\n",
    "    df = df.drop_duplicates(subset=['target_bt'])\n",
    "\n",
    "    # Delete rows that are not distinct from raw_train_dataset['source'] or raw_train_dataset['target']\n",
    "    df = df[~df['source_bt'].isin(raw_datasets['train']['source'])]\n",
    "    df = df[~df['target_bt'].isin(raw_datasets['train']['target'])]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean the text\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Convert first character to uppercase\n",
    "    text = text[0].upper() + text[1:]\n",
    "\n",
    "    # # Remove newline characters\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "\n",
    "    # Remove white space after $\n",
    "    text = re.sub(r\"([$])\\s+\", r\"\\1\", text)\n",
    "\n",
    "    # Remove white space trailing punctuation end of sentence\n",
    "    text = re.sub(r\"\\s+([.,!?%])\", r\"\\1\", text)\n",
    "\n",
    "    # Remove white space before contractions (e.g., \"I 'm John\" becomes \"I'm John\")\n",
    "    text = re.sub(r\"\\s\\'(s|t|ve|ll|d|re|m)\\b\", r\"'\\1\", text)\n",
    "\n",
    "    # Remove white space around text within double quotes\n",
    "    text = re.sub(r'\"(\\s*.*?\\s*)\"', r'\"\\1\"', text)\n",
    "\n",
    "    # Remove white space around text within single quotes\n",
    "    text = re.sub(r\"'(\\s*.*?\\s*)'\", r\"'\\1'\", text)\n",
    "\n",
    "    # Remove white space around text within parentheses\n",
    "    text = re.sub(r\"\\((\\s*.*?\\s*)\\)\", r\"(\\1)\", text)\n",
    "\n",
    "    # Remove white space around text within square brackets\n",
    "    text = re.sub(r\"\\[(\\s*.*?\\s*)\\]\", r\"[\\1]\", text)\n",
    "\n",
    "    # Remove white space around text within curly brackets\n",
    "    text = re.sub(r\"\\{(\\s*.*?\\s*)\\}\", r\"{\\1}\", text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def clean_df(df):\n",
    "    \"\"\"\n",
    "    Cleans the dataframe\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): dataframe to be cleaned\n",
    "\n",
    "    Returns:\n",
    "        cleaned dataframe\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Clean the source and target sentences\n",
    "    df['source_bt'] = df['source_bt'].apply(clean_text)\n",
    "    df['target_bt'] = df['target_bt'].apply(clean_text)\n",
    "\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates(subset=['source_bt'])\n",
    "    df = df.drop_duplicates(subset=['target_bt'])\n",
    "\n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_filters(df, acceptability_threshold_source=ACCEPTABILITY_THRESHOLD_SOURCE, acceptability_threshold_target=ACCEPTABILITY_THRESHOLD_TARGET, similarity_threshold=SIMILARITY_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Adds toxicity, acceptability and similarity scores to the dataframe and calculates filters for the candidate sentence pairs.\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): dataframe of back translated sentences\n",
    "        acceptability_threshold_source (float): acceptability threshold for source sentences\n",
    "        acceptability_threshold_target (float): acceptability threshold for target sentences\n",
    "        similarity_threshold (float): similarity threshold for candidate sentence pairs\n",
    "\n",
    "    Returns:\n",
    "        dataframe with toxicity, acceptability and similarity scores and filters for the candidate sentence pairs\n",
    "    \"\"\"\n",
    "    # Convert source_bt and target_bt to lists\n",
    "    source_bt = df[\"source_bt\"].tolist()\n",
    "    target_bt = df[\"target_bt\"].tolist()\n",
    "    \n",
    "    # Calculate toxicity scores for the candidate sentence pairs\n",
    "    df['source_bt_toxicity'] = calc_tox_acceptability(source_bt, tokenizer_toxicity, model_toxicity, output_score=False, output_mean=False)\n",
    "    df['target_bt_toxicity'] = calc_tox_acceptability(target_bt, tokenizer_toxicity, model_toxicity, output_score=False, output_mean=False)\n",
    "\n",
    "    # Calculate acceptability scores for the candidate sentence pairs\n",
    "    df['source_bt_acceptability'] = calc_tox_acceptability(source_bt, tokenizer_acceptability, model_acceptability, output_score=True, output_mean=False)\n",
    "    df['target_bt_acceptability'] = calc_tox_acceptability(target_bt, tokenizer_acceptability, model_acceptability, output_score=True, output_mean=False)\n",
    "\n",
    "    # Calculate similarity scores for the candidate sentence pairs - return the F1 score\n",
    "    df['bt_similarity'] = calc_bert_score(source_bt, target_bt, output_mean=False)[2]\n",
    "\n",
    "    # Create filters for the candidate sentence pairs\n",
    "    ## Filter 1: Toxicity\n",
    "    df['f_toxicity'] = (df['source_bt_toxicity'] == 1) & (df['target_bt_toxicity'] == 0)\n",
    "\n",
    "    ## Filter 2: Acceptability\n",
    "    df['f_acceptability'] = (df['source_bt_acceptability'] >= acceptability_threshold_source) & (df['target_bt_acceptability'] >= acceptability_threshold_target)\n",
    "\n",
    "    ## Filter 3: Similarity\n",
    "    df['f_similarity'] = (df['bt_similarity'] >= similarity_threshold)\n",
    "  \n",
    "    # Delete redundant columns\n",
    "    df = df.drop(columns=['source_bt_toxicity', 'target_bt_toxicity', 'source_bt_acceptability', 'target_bt_acceptability', 'bt_similarity'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_filtered_df(df, f_toxicity, f_acceptability, f_similarity):\n",
    "    \"\"\"\n",
    "    Creates a filtered dataframe based on the filters provided, adds the original source and target sentences, removes duplicates, and returns the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): dataframe to be filtered\n",
    "        f_toxicity (bool): whether to filter based on toxicity\n",
    "        f_acceptability (bool): whether to filter based on acceptability\n",
    "        f_similarity (bool): whether to filter based on similarity\n",
    "\n",
    "    Returns:\n",
    "        filtered dataframe\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df = df.copy()\n",
    "\n",
    "    # Apply filters\n",
    "    if f_toxicity:\n",
    "        df = df[df['f_toxicity'] == True]\n",
    "    if f_acceptability:\n",
    "        df = df[df['f_acceptability'] == True]\n",
    "    if f_similarity:\n",
    "        df = df[df['f_similarity'] == True]\n",
    "\n",
    "    # Drop filter columns\n",
    "    df = df.drop(columns=['f_toxicity', 'f_acceptability', 'f_similarity'])\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={'source_bt': 'source', 'target_bt': 'target'})\n",
    "    \n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def combine_data(df_aug, raw_datasets, sample_size, random_state=RANDOM_SEED):\n",
    "    \"\"\"\n",
    "    Add original data to the top of the dataframe and return a dataset dictionary\n",
    "\n",
    "    Args:\n",
    "        df_aug (dataframe): augmented dataframe with 'source' and 'target' columns\n",
    "        raw_datasets (dataset dictionary): original dataset dictionary\n",
    "        aug_sample (int): number of augmented samples to include\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df_aug = df_aug.copy()\n",
    "\n",
    "    # Randomly sample from the augmented dataframe, setting a seed for reproducibility\n",
    "    df_aug = df_aug.sample(n=sample_size, random_state=random_state)\n",
    "\n",
    "    # Create a dataframe with original source and target sentences\n",
    "    df_orig = pd.DataFrame({'source': raw_datasets['train']['source'], 'target': raw_datasets['train']['target']})\n",
    "\n",
    "    # Concatenate the original source and target sentences into source_bt and target_bt\n",
    "    df_aug = pd.concat([df_orig, df_aug], axis=0)\n",
    "\n",
    "    # Drop duplicates\n",
    "    df_aug = df_aug.drop_duplicates(subset=['source'])\n",
    "    df_aug = df_aug.drop_duplicates(subset=['target'])\n",
    "\n",
    "    # Reset index\n",
    "    df_aug = df_aug.reset_index(drop=True)\n",
    "\n",
    "    # Shuffle the dataframe, using the random seed for reproducibility\n",
    "    df_aug = df_aug.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # Create a dataset dictionary\n",
    "    dataset_dict = DatasetDict({\n",
    "        \"train\": Dataset.from_pandas(df_aug),\n",
    "        \"validation\": raw_datasets[\"validation\"],\n",
    "        \"test\": raw_datasets[\"test\"],\n",
    "    })\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO-DO: Remove the last minute shuffling of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make back-translated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 9/336 [02:06<1:16:45, 14.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a dataframe for back translated sentences\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df_backtranslated \u001b[39m=\u001b[39m make_back_translate_df()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength of df_backtranslated: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(df_backtranslated)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Delete models and clear GPU memory\u001b[39;00m\n",
      "\u001b[1;32m/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb Cell 13\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m# Back translate the sentences and add to pandas dataframe\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msource_bt\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m back_translate(raw_datasets[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msource\u001b[39;49m\u001b[39m'\u001b[39;49m], language_src, language_dst)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtarget_bt\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m back_translate(raw_datasets[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m], language_src, language_dst)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m# Delete rows with duplicate 'source_bt' or 'target_bt'\u001b[39;00m\n",
      "\u001b[1;32m/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m batch \u001b[39m=\u001b[39m texts[i:i \u001b[39m+\u001b[39m batch_size]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mfor\u001b[39;00m lang \u001b[39min\u001b[39;00m language_dst:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     translated_batch \u001b[39m=\u001b[39m translate(batch, tmp_lang_model, tmp_lang_tokenizer, lang)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     back_translated_batch \u001b[39m=\u001b[39m translate(translated_batch, src_lang_model, src_lang_tokenizer, language_src)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m     all_back_translated_texts\u001b[39m.\u001b[39mextend(back_translated_batch)\n",
      "\u001b[1;32m/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdel\u001b[39;00m tokens\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdel\u001b[39;00m translated\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m cleanup()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m translated_texts\n",
      "\u001b[1;32m/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcleanup\u001b[39m():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m    Cleans up the GPU memory.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     gc\u001b[39m.\u001b[39;49mcollect()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/2_Data_Augmentation.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a dataframe for back translated sentences\n",
    "df_backtranslated = make_back_translate_df()\n",
    "print(f\"Length of df_backtranslated: {len(df_backtranslated)}\")\n",
    "\n",
    "# Delete models and clear GPU memory\n",
    "del tmp_lang_model\n",
    "del tmp_lang_tokenizer\n",
    "del src_lang_model\n",
    "del src_lang_tokenizer\n",
    "cleanup()\n",
    "\n",
    "# Export df_backtranslated to pickle\n",
    "df_backtranslated.to_pickle(\"../data/interim/df_backtranslated.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean back-translated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of df_backtranslated: 66588\n",
      "Length of df_backtranslated_cleaned: 66580\n"
     ]
    }
   ],
   "source": [
    "df_backtranslated = pd.read_pickle(\"../data/interim/df_backtranslated.pkl\")\n",
    "df_backtranslated_cleaned = clean_df(df_backtranslated)\n",
    "print(f\"Length of df_backtranslated: {len(df_backtranslated)}\")\n",
    "print(f\"Length of df_backtranslated_cleaned: {len(df_backtranslated_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add filters to the back-translated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer_toxicity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df_backtranslated_with_filters \u001b[39m=\u001b[39m calc_filters(df_backtranslated_cleaned)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df_backtranslated_with_filters\u001b[39m.\u001b[39mto_pickle(\u001b[39m\"\u001b[39m\u001b[39m../data/interim/df_backtranslated_with_filters.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(df_backtranslated) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(df_backtranslated_with_filters)\n",
      "\u001b[1;32m/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=171'>172</a>\u001b[0m target_bt \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mtarget_bt\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=173'>174</a>\u001b[0m \u001b[39m# Calculate toxicity scores for the candidate sentence pairs\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=174'>175</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msource_bt_toxicity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m calc_tox_acceptability(source_bt, tokenizer_toxicity, model_toxicity, output_score\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, output_mean\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=175'>176</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtarget_bt_toxicity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m calc_tox_acceptability(target_bt, tokenizer_toxicity, model_toxicity, output_score\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, output_mean\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdeeplearning6-vm.europe-west4-b.w266-401709/home/garykong/w266_final_project/notebooks/3_Data_Augmentation.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=177'>178</a>\u001b[0m \u001b[39m# Calculate acceptability scores for the candidate sentence pairs\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer_toxicity' is not defined"
     ]
    }
   ],
   "source": [
    "df_backtranslated_with_filters = calc_filters(df_backtranslated_cleaned)\n",
    "df_backtranslated_with_filters.to_pickle(\"../data/interim/df_backtranslated_with_filters.pkl\")\n",
    "assert len(df_backtranslated) == len(df_backtranslated_with_filters)\n",
    "\n",
    "# Delete models and clear GPU memory\n",
    "del tokenizer_toxicity\n",
    "del model_toxicity\n",
    "del tokenizer_acceptability\n",
    "del model_acceptability\n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create dataframes with filters applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with all filters: 15427\n",
      "Number of rows with no toxicity filter:  23572\n",
      "Number of rows with no acceptability filter:  21620\n",
      "Number of rows with no similarity filter:  34109\n"
     ]
    }
   ],
   "source": [
    "df_all_filters = create_filtered_df(df=df_backtranslated_with_filters, f_toxicity=True, f_acceptability=True, f_similarity=True)\n",
    "df_no_toxicity_filter = create_filtered_df(df=df_backtranslated_with_filters, f_toxicity=False, f_acceptability=True, f_similarity=True)\n",
    "df_no_acceptability_filter = create_filtered_df(df=df_backtranslated_with_filters, f_toxicity=True, f_acceptability=False, f_similarity=True)\n",
    "df_no_similarity_filter = create_filtered_df(df=df_backtranslated_with_filters, f_toxicity=True, f_acceptability=True, f_similarity=False)\n",
    "\n",
    "print(f\"Number of rows with all filters: {len(df_all_filters)}\")\n",
    "print(\"Number of rows with no toxicity filter: \", len(df_no_toxicity_filter))\n",
    "print(\"Number of rows with no acceptability filter: \", len(df_no_acceptability_filter))\n",
    "print(\"Number of rows with no similarity filter: \", len(df_no_similarity_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add original data to augmented data and create dataset dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in aug_datasets_all_filters: 20711\n",
      "Number of rows in aug_datasets_no_toxicity_filter: 20711\n",
      "Number of rows in aug_datasets_no_acceptability_filter: 20711\n",
      "Number of rows in aug_datasets_no_similarity_filter: 20711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14db57b5d6254bbca2c0fe4d68fd94ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/20711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7193fcc9cf09440c99e80ed8b6dc2b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646a6409dc364fdd9049d4efa7c5881f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5130a200e3c64c5e9c295f93218fc2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/20711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab933c3e88e482199a9bed6e37bd604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020026065d214fc8b381c446ce11222f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239e63ecf6b0478fbea05c43f46b1801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/20711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bfe691281941c29d807cd95a6d5d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d35e075c15452db946ff692b74195f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915c213af29246e49bacbd9e4c1677af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/20711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebcc5d23669487cafaefe3479098b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fd165659ff42ba8a35b6a3160ca92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine data\n",
    "aug_datasets_all_filters = combine_data(df_all_filters, raw_datasets, SAMPLE_SIZE)\n",
    "aug_datasets_no_toxicity_filter = combine_data(df_no_toxicity_filter, raw_datasets, SAMPLE_SIZE)\n",
    "aug_datasets_no_acceptability_filter = combine_data(df_no_acceptability_filter, raw_datasets, SAMPLE_SIZE)\n",
    "aug_datasets_no_similarity_filter = combine_data(df_no_similarity_filter, raw_datasets, SAMPLE_SIZE)\n",
    "\n",
    "# Print number of rows in each\n",
    "print(f\"Number of rows in aug_datasets_all_filters: {len(aug_datasets_all_filters['train'])}\")\n",
    "print(f\"Number of rows in aug_datasets_no_toxicity_filter: {len(aug_datasets_no_toxicity_filter['train'])}\")\n",
    "print(f\"Number of rows in aug_datasets_no_acceptability_filter: {len(aug_datasets_no_acceptability_filter['train'])}\")\n",
    "print(f\"Number of rows in aug_datasets_no_similarity_filter: {len(aug_datasets_no_similarity_filter['train'])}\")\n",
    "\n",
    "# Export augmented datasets to pickle\n",
    "aug_datasets_all_filters.save_to_disk(\"../data/processed/aug_datasets_all_filters\")\n",
    "aug_datasets_no_toxicity_filter.save_to_disk(\"../data/processed/aug_datasets_no_toxicity_filter\")\n",
    "aug_datasets_no_acceptability_filter.save_to_disk(\"../data/processed/aug_datasets_no_acceptability_filter\")\n",
    "aug_datasets_no_similarity_filter.save_to_disk(\"../data/processed/aug_datasets_no_similarity_filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
